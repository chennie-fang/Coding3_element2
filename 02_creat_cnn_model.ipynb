{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. creat a model\n",
    "#### In this notebook I will use the classification recognition function of CNN to make a model to be used later in the Deepdream. I will replace the weights of the pre-trained model in deepdream with the weights of this model.\n",
    "\n",
    "code from: https://www.tensorflow.org/api_docs/python/tf/keras/Model#compute_metrics\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ！You can skip this step and use the model I've already trained, it's in the folder and it ends in weight.h5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then let's do some import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T07:45:55.173545500Z",
     "start_time": "2024-06-04T07:45:46.271495100Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalMaxPooling1D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T07:45:55.184584900Z",
     "start_time": "2024-06-04T07:45:55.174826600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pre-processed data\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)  # Use 20% of the data as a validation set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T07:45:55.501958700Z",
     "start_time": "2024-06-04T07:45:55.298848Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3189 images belonging to 2 classes.\n",
      "Found 796 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Training data generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    './dataset/',   # Dataset path\n",
    "    target_size=(299, 299),  \n",
    "    batch_size=32,\n",
    "    class_mode='categorical',  # Applicable to binary classification problems(from chatgpt)\n",
    "    subset='training',  \n",
    "    shuffle=True  \n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    './dataset/',  # Dataset path\n",
    "    target_size=(299, 299),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',  \n",
    "    shuffle=True \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T07:45:58.660153100Z",
     "start_time": "2024-06-04T07:45:55.418948200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Defining the model (The pre-trained model used here is going to be the same as the pre-trained model in deepdream.)\n",
    "model = tf.keras.applications.InceptionV3(include_top=True, weights=None,classes=2)\n",
    "#model.summary()\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss=keras.losses.CategoricalCrossentropy(), metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T07:52:01.866218100Z",
     "start_time": "2024-06-04T07:46:09.672358600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chennifang/miniconda3/envs/tf210/lib/python3.9/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m362s\u001b[0m 4s/step - accuracy: 0.7940 - loss: 0.7197 - val_accuracy: 0.8659 - val_loss: 0.3918\n",
      "Epoch 2/3\n",
      "\u001b[1m 1/99\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:25\u001b[0m 3s/step - accuracy: 0.9688 - loss: 0.1631"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 00:13:13.444475: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "/Users/chennifang/miniconda3/envs/tf210/lib/python3.9/contextlib.py:137: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9688 - loss: 0.1631 - val_accuracy: 0.8929 - val_loss: 0.3431\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 00:13:14.216553: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m349s\u001b[0m 4s/step - accuracy: 0.8646 - loss: 0.4086 - val_accuracy: 0.8659 - val_loss: 0.4099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
    "    epochs=3\n",
    ")\n",
    "\n",
    "# save model\n",
    "model.save('sea_hares_cnn.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#save weight\n",
    "model.save_weights('sea_hares_cnn.weight.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coding3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
